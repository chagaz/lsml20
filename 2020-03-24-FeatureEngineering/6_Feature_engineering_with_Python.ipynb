{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering with Python\n",
    "After this 2 hours practical, you will be able to\n",
    "- preprocess main data types (numerical, various categorical, time data)\n",
    "- understand the challenges of high dimension\n",
    "- evaluate and optimize your feature engineering\n",
    "\n",
    "The content is quite dense. You can run it in a \"blackbox\" way, but you are encouraged to go back to it later to deepend your understanding. You can see today as a toolbox with working examples. We have tried to use \"real world datasets\" as much as possible.\n",
    "\n",
    "#### What is feature engineering?\n",
    "Very vague notion, mainly all transformation to go from raw data to input of your final ML pipeline. Can be standard or ad-hoc creative transformation of your data. A lot of constraints influence your feature engineering\n",
    "- extract meaningful information from data\n",
    "- transform your data to respect mathematical constraints of algorithms\n",
    "- reduction of dimensions\n",
    "\n",
    "Let's see how it works in practice. It may seem a bit chaotic, but there are actually some rules that help! \n",
    "<img src=\"machine_learning_2x.png\" style=\"width: 300px;\">\n",
    "\n",
    "# Table of contents\n",
    "1. [Date features](#dates)\n",
    "    1. [Turn timestamps into categorical features](#dateToCategorical)\n",
    "    2. [How to best deal with categorical features](#CategoricalEncoding)\n",
    "    3. [How about big data?](#BigData)\n",
    "2. [Numerical features](#numerical)\n",
    "3. [Dimensionality reduction](#PCA)\n",
    "\n",
    "There are a few questions to help you interprete the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup your notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as spstats\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, roc_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Date features <a name=\"dates\"></a>\n",
    "\n",
    "A word about data.\n",
    "The dataset contains 9358 instances of hourly averaged responses from an array of 5 metal oxide chemical sensors embedded in an Air Quality Chemical Multisensor Device. The device was located on the field in a significantly polluted area, at road level,within an Italian city. Data were recorded from March 2004 to February 2005 (one year)representing the longest freely available recordings of on field deployed air quality chemical sensor devices responses. Ground Truth hourly averaged concentrations for CO, Non Metanic Hydrocarbons, Benzene, Total Nitrogen Oxides (NOx) and Nitrogen Dioxide (NO2) and were provided by a co-located reference certified analyzer.\n",
    "\n",
    "A lot of things can be done with this dataset, for our practical, we will just consider a time series problem, to predict the true CO concentration CG(GT) from the timestamp, and other parameters easy to acquire like Temperature, relative and absolute humidity (RH, AH). This way we can monitor CO level without a sensor. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first get the data\n",
    "airdata = pd.read_csv('AirQualityUCI.csv', sep=';', decimal=b',', na_values=-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have a look\n",
    "airdata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have a more informative look!\n",
    "airdata.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first two columns are categorical (date, time), others are numerical. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.clustermap(airdata[airdata.columns[2:-2]].corr(), cmap=\"vlag\", vmin=-1, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Turn timestamps into categorical features <a name=\"dateToCategorical\"></a>\n",
    "To exploit the timestamps, we are going to use the [pandas timeseries functions](https://pandas.pydata.org/pandas-docs/stable/timeseries.html) to extract meaningful categorical features like the day in the week, the month etc. We can consider other more complex variables like season, if it is a holiday etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we drop Nan values for the variables we care about\n",
    "airdata_nona = airdata.dropna(subset=['CO(GT)', 'Date', 'Time', 'T', 'AH', 'RH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some conversion work\n",
    "airdata_nona = airdata_nona.assign(date_format = pd.to_datetime(airdata_nona.Date))\n",
    "airdata_nona.index=airdata_nona.date_format\n",
    "airdata_nona = airdata_nona.assign(day_year=airdata_nona.date_format.dt.dayofyear)\n",
    "airdata_nona = airdata_nona.assign(day_week=airdata_nona.date_format.dt.dayofweek)\n",
    "airdata_nona = airdata_nona.assign(weekname=airdata_nona.date_format.dt.week)\n",
    "airdata_nona = airdata_nona.assign(month=airdata_nona.date_format.dt.month)\n",
    "airdata_nona = airdata_nona.assign(hour=airdata_nona.Time.str[:-6].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we limit ourselves to a reduced time window in which the measures are dense.\n",
    "airdata_nona_small = airdata_nona[(airdata_nona.date_format>='2004-04-01')&(airdata_nona.date_format<='2005-04-30')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some sanity check.\n",
    "print(airdata.shape, airdata_nona.shape, airdata_nona_small.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation setup\n",
    "to go further, we need a train-test split. The goal is to see how a good preprocess of inputs leads to better predictions.\n",
    "the data is kind of complicated, we cannot just randomly divide in train and test!! Indeed, if I have the level of CO some day at 3pm, provided my model is complex enough to get the info, I might have data leakage and bias my prediction of the CO level at 4pm the same day in the test set. Let us get as a test set with 12 random weeks.\n",
    "\n",
    "We also have to choose a metric for evaluation. Let's gor for the [mean absolute error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html), and a regression algorithm. Let's go for simple [linear ridge regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). We could have something fancier and better performance, but we are interested in feature engineering here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get train test split.\n",
    "np.random.seed(4697)\n",
    "test_weeks = np.random.choice(airdata_nona_small.weekname.unique(), 12, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = airdata_nona_small[~airdata_nona_small.weekname.isin(test_weeks)]\n",
    "testing_set = airdata_nona_small[airdata_nona_small.weekname.isin(test_weeks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a first model! This will be our reference for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variable_list = ['T', 'AH', 'RH', 'month', 'day_week', 'hour']\n",
    "X_train = training_set[variable_list]\n",
    "Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "X_test = testing_set[variable_list]\n",
    "Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('train MAE\\t', mean_absolute_error(Y_train, clf.predict(X_train)), '\\t; test MAE\\t', mean_absolute_error(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do models adding one variable at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, variable in enumerate(variable_list):\n",
    "    X_train = training_set[variable_list[:i+1]]\n",
    "    Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "    X_test = testing_set[variable_list[:i+1]]\n",
    "    Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "    clf = Ridge(alpha=1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print('train MAE\\t', mean_absolute_error(Y_train, clf.predict(X_train)), '\\t; test MAE\\t', mean_absolute_error(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Why have we done this last experiment? what does it teach us?\n",
    "\n",
    "Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### B. How to best deal with categorical features <a name=\"CategoricalEncoding\"></a>\n",
    "For now, we have not really thought about it, we are lucky and our categorical data have a natural numeric representation. It is called [Label encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). But there are other possibilities, like [one hot encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder), also called [dummy encoding](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='day_week', y='CO(GT)', data=training_set, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='hour', y='CO(GT)', data=training_set, showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x='month', y='CO(GT)', data=training_set, showfliers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Let's sum up. We have transformed useless time data into several useful categorical data like day of the week, hour in the day, month, they naturally have some numerical value (January is 1 etc), or the hour of the day is numerical. This is called [Label encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)\n",
    "\n",
    "**Question** Given we consider a linear model, briefly explain why one hot encoding might work better for this dataset.\n",
    "\n",
    "Answer here\n",
    "\n",
    "\n",
    "Let's look at each variable among day_week, hour and month, and see if it works better with label encoding or one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for variable in ['day_week', 'hour', 'month']:\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(training_set[variable].as_matrix().reshape(-1, 1))\n",
    "    X_train_hot = enc.fit_transform(training_set[variable].as_matrix().reshape(-1, 1))\n",
    "    X_train = training_set[variable].as_matrix().reshape(-1, 1)\n",
    "    Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "    X_test_hot = enc.transform(testing_set[variable].as_matrix().reshape(-1, 1))\n",
    "    X_test = testing_set[variable].as_matrix().reshape(-1, 1)\n",
    "    Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "    clf = Ridge(alpha=1)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    clf_hot = Ridge(alpha=1)\n",
    "    clf_hot.fit(X_train_hot, Y_train)\n",
    "    print(variable, '\\ttrain MAE  ', np.round(mean_absolute_error(Y_train, clf.predict(X_train)), 2), '; test MAE  ', np.round(mean_absolute_error(Y_test, clf.predict(X_test)),2),  '\\t; dummy train MAE  ', np.round(mean_absolute_error(Y_train, clf_hot.predict(X_train_hot)), 2), '\\t; dummy test MAE  ', np.round(mean_absolute_error(Y_test, clf_hot.predict(X_test_hot)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do you think of those results??\n",
    "\n",
    "Answere here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final best perf with all 3 variables in ont hot encoding\n",
    "X = pd.get_dummies(airdata_nona_small, columns=['day_week', 'hour', 'month'])\n",
    "col_list = [c for c in X.columns if '_' in c]\n",
    "col_list.remove('day_year')\n",
    "col_list.remove('date_format')\n",
    "col_list += ['T', 'RH', 'AH']\n",
    "X_train = X[~X.weekname.isin(test_weeks)][col_list]\n",
    "X_test = X[X.weekname.isin(test_weeks)][col_list]\n",
    "Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('train MAE\\t', mean_absolute_error(Y_train, clf.predict(X_train)), '\\t; test MAE\\t', mean_absolute_error(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Are you convinced?\n",
    "\n",
    "Answer here\n",
    "\n",
    "Further understanding can be achieved by looking at the weights found by the model in the label encoding and in the one hot encoding\n",
    "\n",
    "\n",
    "\n",
    "### C. How about big data? <a name=\"BigData\"></a>\n",
    "Ok, fine, amazing performances! But our categorical variables were kind of nice, and do not have thousands of possible values. In that case we could not binarize everything. What are we going to do??\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/0*FwubnnoNlt6Coo9j.png\">\n",
    "\n",
    "Let's imagine we have a categorical variable with many possible values. A few real world examples could be airports in flight delay data (there are >5k public airports in the US!!!), or IP addresses. \n",
    "\n",
    "Let us imagine it is not possible to binarize hours of the day (imagine we have a record every minute for instance). We could group the minutes by bins. Or we could consider the average of the target variable for that minute! Let's do that for hours in the day. It may seem weird, but if we stick to our train data, no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's build our average. We are very careful and use only the train set !!\n",
    "X_train = airdata_nona_small[~airdata_nona_small.weekname.isin(test_weeks)]\n",
    "match_time = X_train.groupby('Time')['CO(GT)'].mean().to_frame()\n",
    "match_day = X_train.groupby('day_week')['CO(GT)'].mean().to_frame()\n",
    "match_month = X_train.groupby('month')['CO(GT)'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's add our new features to the dataset!!!!\n",
    "X_time = pd.merge(airdata_nona_small, match_time, left_on='Time', right_index=True, suffixes=['', '_time'])\n",
    "X_time_day = pd.merge(X_time, match_day, left_on='day_week', right_index=True, suffixes=['', '_day'])\n",
    "X_time_day_month = pd.merge(X_time_day, match_month, left_on='month', right_index=True, suffixes=['', '_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's test our brand new features!!!!\n",
    "# we want the list of course\n",
    "tmp_list = [c for c in X_time_day_month.columns if '_' in c]\n",
    "tmp_list.remove('date_format')\n",
    "tmp_list.remove('day_year')\n",
    "tmp_list.remove('day_week')\n",
    "col_list = tmp_list + ['T', 'RH', 'AH']\n",
    "# and then ususal performance measuring setup.\n",
    "X_train = X_time_day_month[~X_time_day_month.weekname.isin(test_weeks)][col_list]\n",
    "X_test = X_time_day_month[X_time_day_month.weekname.isin(test_weeks)][col_list]\n",
    "Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('train MAE \\t', mean_absolute_error(Y_train, clf.predict(X_train)), '\\t; test MAE\\t', mean_absolute_error(Y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do you think of this result? Can we expect that result if we have a look back at the boxplots made earlier?\n",
    "\n",
    "Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, no improvement with feature engineering happens all the time. Feature engineering is an art, and most of the time what you try does not work. Just keep this trick in mind for the day it might apply. Other ideas (not exhaustive)\n",
    "- only keep the N most frequent possibilites for one hot encoding\n",
    "- pre-cluster the possibilities, either there is a natural structure (like day/night for hours, seasons for months), or just use other features to run your favorite clustering algorithm\n",
    "\n",
    "\n",
    "## 2. Numerical features <a name=\"numerical\"></a>\n",
    "Ok, actually we have not looked at all at numerical features, and there may be some work to do there as well! First thing is to plot the distribution, remove potential outliers. Let's look at our target variable CO(GT)!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(airdata_nona_small['CO(GT)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about the distribution? Are there outliers? What probability law can you recognize (or not)? Why? Can you think of a transformation we could apply to data? \n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.distplot(np.log(airdata_nona_small['CO(GT)']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went for the log. You can find more about [log-normal distribution](https://en.wikipedia.org/wiki/Log-normal_distribution). Let's see if performance is higher with normally-distributed target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final best perf\n",
    "X = pd.get_dummies(airdata_nona_small, columns=['day_week', 'hour', 'month'])\n",
    "col_list = [c for c in X.columns if '_' in c]\n",
    "col_list.remove('day_year')\n",
    "col_list.remove('date_format')\n",
    "col_list += ['T', 'RH', 'AH']\n",
    "X_train = X[~X.weekname.isin(test_weeks)][col_list]\n",
    "X_test = X[X.weekname.isin(test_weeks)][col_list]\n",
    "Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "clf = Ridge(alpha=1)\n",
    "clf.fit(X_train, np.log(Y_train))\n",
    "print('train MAE log target \\t', mean_absolute_error(Y_train, np.exp(clf.predict(X_train))), '\\t; test MAE log target\\t', mean_absolute_error(Y_test, np.exp(clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a little improvement here as well. Most algorithms deal better with regular normally-distributed data. Another possible transformation is the [box-cox](https://en.wikipedia.org/wiki/Power_transform). It is close to the logarithm, but more parametrizable to really obtain a normal distribution. In our case, it works the same as the log, but to keep in your toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def invboxcox(y,ld):\n",
    "   if ld == 0:\n",
    "      return(np.exp(y))\n",
    "   else:\n",
    "      return(np.exp(np.log(ld*y+1)/ld))\n",
    "    \n",
    "l, opt_lambda = spstats.boxcox(Y_train)    \n",
    "# final best perf\n",
    "X = pd.get_dummies(airdata_nona_small, columns=['day_week', 'hour', 'month'])\n",
    "col_list = [c for c in X.columns if '_' in c]\n",
    "col_list.remove('day_year')\n",
    "col_list.remove('date_format')\n",
    "col_list += ['T', 'RH', 'AH']\n",
    "X_train = X[~X.weekname.isin(test_weeks)][col_list]\n",
    "X_test = X[X.weekname.isin(test_weeks)][col_list]\n",
    "Y_train = training_set['CO(GT)'].as_matrix().ravel()\n",
    "Y_test = testing_set['CO(GT)'].as_matrix().ravel()\n",
    "clf = Ridge(alpha=1)\n",
    "l, opt_lambda = spstats.boxcox(Y_train) \n",
    "clf.fit(X_train, l)\n",
    "print(mean_absolute_error(Y_train, invboxcox(clf.predict(X_train), opt_lambda)), mean_absolute_error(Y_test, invboxcox(clf.predict(X_test), opt_lambda)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's have a look at the distribution!!\n",
    "sns.distplot(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What can you say about this distribution? Which one looks closer to a gaussian between box-cox and log? Does box-cox improve performance here? decrease?\n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality reduction <a name=\"PCA\"></a>\n",
    "Another case where feature engineering is crucial is when you have too many features. This is painful to store, very long to run an algorithm, even to make a prediction. Moreover, there might be noise in your data, and dimensionality reduction can even improve your performance!! There are many methods, to learn a new space of smaller dimension called [manifold](http://scikit-learn.org/stable/modules/manifold.html#locally-linear-embedding) where your data lives, or to [reduce the dimensions](http://scikit-learn.org/stable/modules/unsupervised_reduction.html). Here we will detail an example of PCA.\n",
    "\n",
    "So let's switch to a new dataset. It consists in mutant p53 proteins, i.e. the p53 protein, a key protein for cancer, has a modification. The goal is to predict from physical measurements whether it is still active or not. There are a total of 5409 attributes per instance. \n",
    "\n",
    "- Attributes 1-4826 represent 2D electrostatic and surface based features. \n",
    "- Attributes 4827-5408 represent 3D distance based features. \n",
    "- Attribute 5409 is the class attribute, which is either active or inactive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's read the data. \n",
    "active = pd.read_csv('K9_active.csv', header=None, na_values='?')\n",
    "inactive = pd.read_csv('K9_inactive3000.csv', header=None, na_values='?')\n",
    "data = pd.concat((active, inactive), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop na\n",
    "data = data.dropna(subset=range(5408))\n",
    "data[5408].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data - separate in train-test-split\n",
    "X = data[list(range(5408))].as_matrix()\n",
    "Y = (data[[5408]]=='inactive').astype(bool).astype(int).as_matrix().ravel()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train a logistic regression model, and display results\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance evaluaion - accuracy\n",
    "logistic.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What other metrics can we use to evaluate a classification? Are they more thorough?\n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance evaluaion - ROC curve\n",
    "fpr, tpr, _ = roc_curve(Y_test, logistic.decision_function(X_test))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='linear classif')\n",
    "plt.legend(loc='best')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of dimensions. Are they all useful? Let's apply a Principal Component Analysis. You can find a good introduction to PCA [here](https://web.stanford.edu/~hastie/Papers/ESLII.pdf), in setion 14.5. Very important: always standardize your variables before applying PCA. To do it in a clean way, we are using Scikit-learn' [pipelines](http://scikit-learn.org/stable/modules/pipeline.html#pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's apply PCA\n",
    "target_names = Y_train\n",
    "\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=500))\n",
    "X_r = std_clf.fit(X_train).transform(X_train)\n",
    "\n",
    "pca_std = std_clf.named_steps['pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How do we choose the number of components: Percentage of variance explained for each components\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.clf()\n",
    "plt.axes([.2, .2, .7, .7])\n",
    "plt.plot(np.cumsum(pca_std.explained_variance_ratio_), linewidth=2)\n",
    "plt.axis('tight')\n",
    "plt.xlabel('n_components')\n",
    "plt.ylabel('explained_variance_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** We have represented the cumulative explained variance as a function of the number of retained components. Does it keep improving at the same pace? When does the improvement slow down? What can you deduce for the number of informative components? What other criteria could be used to choose the number of components?\n",
    "\n",
    "Answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA can also be used to visualize data.\n",
    "plt.figure(2)\n",
    "plt.subplot(121)\n",
    "colors = ['darkorange', 'navy']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [1, 0], target_names):\n",
    "    plt.scatter(X_r[Y_train == i, 0], X_r[Y_train == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                label=str(i))\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.title('PCA of P53 dataset (PC2 vs PC1)')\n",
    "\n",
    "plt.subplot(122)\n",
    "colors = ['darkorange', 'navy']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [1, 0], target_names):\n",
    "    plt.scatter(X_r[Y_train == i, 7], X_r[Y_train == i, 2], color=color, alpha=.8, lw=lw,\n",
    "                label=str(i))\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.xlabel('PCA8')\n",
    "plt.ylabel('PCA3')\n",
    "plt.title('PCA of P53 dataset (PC3 vs PC8)')\n",
    "\n",
    "plt.subplots_adjust(left=.1, wspace=1, top=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comment.\n",
    "\n",
    "here\n",
    "\n",
    "Now let's see how it affects classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's choose a number of components to use in classification (try to vary it and look how it affects results.)\n",
    "N_features = 90\n",
    "\n",
    "# let's run the same logistic regression as before, with our new input features\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_r[:,:N_features], Y_train)\n",
    "\n",
    "X_test_r = std_clf.transform(X_test)[:,:N_features]\n",
    "fpr_r, tpr_r, _ = roc_curve(Y_test, logistic.decision_function(X_test_r))\n",
    "\n",
    "print(logistic.score(X_test_r, Y_test))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.plot(fpr, tpr, label='linear classif')\n",
    "plt.plot(fpr_r, tpr_r, label='PCA{} + linear classif'.format(N_features))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the seed, you may already have very good performances with the original features. With PCA, you have results at least as good with 50 times fewer dimensions!! As an exercise, you can also try to make 2 distinct PCAs for the 2 types of features in the dataset, as they may have different variances. Here you already have satisfying results, but that is a trick to remember.\n",
    "\n",
    "There are many other methods to achieve reduction of dimension. See chapter 14 of the Elements of statistical learning, Hastie, Tibshirani, Friedman and scikit learn documentation [here](http://scikit-learn.org/stable/modules/decomposition.html) or [here](http://scikit-learn.org/stable/modules/manifold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets origins\n",
    "The **P53 dataset** is adapted from [UCI](https://archive.ics.uci.edu/ml/datasets/p53+Mutants), originally extracted from the following papers\n",
    "\n",
    "Danziger, S.A., Baronio, R., Ho, L., Hall, L., Salmon, K., Hatfield, G.W., Kaiser, P., and Lathrop, R.H. (2009) Predicting Positive p53 Cancer Rescue Regions Using Most Informative Positive (MIP) Active Learning, PLOS Computational Biology, 5(9), e1000498 \n",
    "\n",
    "Danziger, S.A., Zeng, J., Wang, Y., Brachmann, R.K. and Lathrop, R.H. (2007) Choosing where to look next in a mutation sequence space: Active Learning of informative p53 cancer rescue mutants, Bioinformatics, 23(13), 104-114. \n",
    "\n",
    "Danziger, S.A., Swamidass, S.J., Zeng, J., Dearth, L.R., Lu, Q., Chen, J.H., Cheng, J., Hoang, V.P., Saigo, H., Luo, R., Baldi, P., Brachmann, R.K. and Lathrop, R.H. (2006) Functional census of mutation sequence spaces: the example of p53 cancer rescue mutants, IEEE/ACM transactions on computational biology and bioinformatics / IEEE, ACM, 3, 114-125. \n",
    "\n",
    "\n",
    "The **Air quality dataset** is used as it is on [UCI](https://archive.ics.uci.edu/ml/datasets/Air+Quality#), originally extracted from the following paper\n",
    "\n",
    "S. De Vito, E. Massera, M. Piga, L. Martinotto, G. Di Francia, On field calibration of an electronic nose for benzene estimation in an urban pollution monitoring scenario, Sensors and Actuators B: Chemical, Volume 129, Issue 2, 22 February 2008, Pages 750-757, ISSN 0925-4005. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few references to go further, but mostly practice ;)\n",
    "\n",
    "https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.04-Feature-Engineering.ipynb \n",
    "\n",
    "https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/notebooks/Ch04_Feature_Engineering_and_Selection/Feature%20Engineering%20on%20Numeric%20Data.ipynb\n",
    "\n",
    "https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n",
    "\n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa (series of 4 blog articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
