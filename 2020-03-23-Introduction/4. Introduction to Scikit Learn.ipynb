{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn\n",
    "Author: `chloe-agathe.azencott@mines-paristech.fr` based on materials from [Alexandre Gramfort](http://alexandre.gramfort.net/) and [Jake Vanderplas](https://github.com/jakevdp) \n",
    "\n",
    "The goal of this notebook is to learn how to use scikit-learn to solve machine learning problems, and how to evaluate and compare models. We will work with the same Digits data set as in Notebook 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from sklearn.datasets import load_digits \n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "# Get descriptors and target to predict\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Get the shape of the data\n",
    "print(\"Number of samples: %d\" % X.shape[0])\n",
    "print(\"Number of pixels: %d\" % X.shape[1])\n",
    "print(\"Number of classes: %d\" % len(np.unique(y))) # number of unique values in y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dimensionality reduction\n",
    "\n",
    "Each object (image) in this data set is represented using 64 features. This makes plotting all the objects on the same figure difficult. Let us use PCA to project the images on 2 dimensions and visualize them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pca object\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "\n",
    "# Apply to the data\n",
    "X_proj = pca.fit_transform(X)\n",
    "print(X_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the projected data\n",
    "plt.scatter(X_proj[:, 0], # first dimension\n",
    "            X_proj[:, 1], # second dimension\n",
    "            c=y, # color by label\n",
    "            edgecolor='none', # remove dot border\n",
    "            alpha=0.5 # use transparency to better see overlapping dots\n",
    "           ) \n",
    "plt.colorbar(label='digit label', ticks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What do you observe? Do you think the classification problem will be easy or hard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular alternative to PCA, which projects the data linearly, is the [tSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) approach. It is very similar to run in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tSNE object\n",
    "tsne = manifold.TSNE(n_components=2)\n",
    "\n",
    "# Apply to the data\n",
    "X_proj = tsne.fit_transform(X)\n",
    "print(X_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the projected data\n",
    "plt.scatter(X_proj[:, 0], # first dimension\n",
    "            X_proj[:, 1], # second dimension\n",
    "            c=y, # color by label\n",
    "            edgecolor='none', # remove dot border\n",
    "            alpha=0.5 # use transparency to better see overlapping dots\n",
    "           ) \n",
    "plt.colorbar(label='digit label', ticks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What do you observe? Would you rather use the tSNE features or the PCA features for learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering \n",
    "K-means is an algorithm for unsupervised clustering: that is, finding clusters (or groups) in data based on the data attributes alone (not the labels). K-means groups samples based on distances: points get assigned to the cluster to which they are the closest (based on the distance to the centroid), centroids are recomputed, and the procedure is iterated until convergence.\n",
    "\n",
    "In k-means, the number of clusters k is a hyperparameter the user must provide.\n",
    "\n",
    "Let us look at how it performs on the Digits data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a k-means clustering object, for k=10\n",
    "clustering = cluster.KMeans(10)\n",
    "\n",
    "# apply it to the data\n",
    "clusters = clustering.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now look at the cluster centroids (i.e. the mean point of each cluster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.imshow(clustering.cluster_centers_[i].reshape((8, 8)), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even without the labels, the clustering algorithm has identified reasonable representants for each class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the clusters we obtained to the true labels. First, notice that the cluster centroids do not appear in the same order as the true labels (the first one is not necessarily a 1), because an unsupervised algorithm has no means to know what label we would like to assign to a cluster it found. We will start by reassigning cluster labels to match the most common digit in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "pred_labels = np.zeros_like(clusters)\n",
    "for i in range(10):\n",
    "    mask = (clusters == i)\n",
    "    pred_labels[mask] = mode(digits.target[mask])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare these clusters to the true labels, we can look at their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.2f\" % metrics.accuracy_score(y, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.imshow(confusion_matrix(y, pred_labels),\n",
    "           cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.ylabel('true')\n",
    "plt.xlabel('predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Which class was the most difficult to identify for the clustering algorithm? Does this match what you observed when looking at the centroids?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the result of the clustering algorithm using the 2 tSNE dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "# Plot 1\n",
    "ax[0].scatter(X_proj[:, 0], X_proj[:, 1], c=pred_labels, \n",
    "             edgecolor='none', alpha=0.5)\n",
    "ax[0].set_title('learned cluster labels')\n",
    "\n",
    "# Plot 2\n",
    "t = ax[1].scatter(X_proj[:, 0], X_proj[:, 1], c=y, \n",
    "             edgecolor='none', alpha=0.5)\n",
    "ax[1].set_title('true labels')\n",
    "plt.colorbar(t, label='digit label', ticks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get more distinct colors, you can use a different colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "# Plot 1\n",
    "ax[0].scatter(X_proj[:, 0], X_proj[:, 1], c=pred_labels, \n",
    "             edgecolor='none', alpha=0.5,\n",
    "             cmap = plt.cm.get_cmap('rainbow', 10))\n",
    "ax[0].set_title('learned cluster labels')\n",
    "\n",
    "# Plot 2\n",
    "t = ax[1].scatter(X_proj[:, 0], X_proj[:, 1], c=y, \n",
    "             edgecolor='none', alpha=0.5,\n",
    "             cmap = plt.cm.get_cmap('rainbow', 10))\n",
    "ax[1].set_title('true labels')\n",
    "plt.colorbar(t, label='digit label', ticks=range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Which digits are easy to predict? Which ones are confused with which other digits? Does this match the confusion matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Reproduce this analysis using a different number of clusters (e.g. k=7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification\n",
    "So, how well can we learn to separate these images using labeled data?\n",
    "\n",
    "### 3.1 Model validation and selection\n",
    "An very important part of machine learning is __model validation__: that is, determining how well your model will generalize from the training data to future unlabeled data. Using a simple algorithm that returns the stored label for any observation from the data set would result in very good predictions, but would not have _learned_ anything, and would be rubbish at predicting the label of a new handwritten digit.\n",
    "\n",
    "We will therefore systematically split our data in a _training set_, on which we'll use the labels to _learn_, or _train_ the model, and a _test set_, on which we'll only use the labels to evaluate the model's ability to make correct predictions. __Not using test data at train time is absolutely essential to estimating generalization ability.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection \n",
    "Xtrain, Xtest, ytrain, ytest = model_selection.train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a fixed random seed (`random_state`) will ensure you can reproduce your experiments, i.e. always have the same samples in your train (resp. test) set. Someone running the experiments with the same seed on a different computer will have a different train/test split, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What fraction of our data will we use for training? For testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to choose between different machine learning algorithms, or between different values of the hyperparameters of the same algorithm. Of course, we can pick the model with the best performance on the test set. But how will we evaulate its performance?\n",
    "\n",
    "__Question__ Why isn't the performance of the best-performing algorithm on the test set a good estimation of the generalization performance (i.e. performance on new data)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, it is common to use __cross-validation__ on the train set to select the best algorithm/model. The `sklearn.model_selection` module provides cross-validation facilities. In addition, many supervised learning algorithms of scikit-learn can be used with such an internal cross-validation procedure to select optimal hyperparameter(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistic regression \n",
    "\n",
    "[LogisticRegression documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "[LogisticRegressionCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html)\n",
    "\n",
    "The logistic regression implementation of scikit-learn minimizes C x logistic empirical error + regularization. Hence the non-regularized logistic regression is obtained when C is very large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model \n",
    "\n",
    "# Create a logistic regression classifier\n",
    "clf = linear_model.LogisticRegression(penalty='l2', \n",
    "                                      C=1e8) # large value of C = no regularization\n",
    "\n",
    "# Fit the classifier on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Apply the classifier to test data\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the accuracy of this classifier? Display its confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can regularization improve this performance? Let us look at what happens when we change this parameter. We will use a cross-validation on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of values for C\n",
    "c_values = np.logspace(-5, 5, num=11)\n",
    "print c_values\n",
    "\n",
    "accuracies = [] # where to store mean accuracy for each value of C\n",
    "for c_val in c_values:\n",
    "    # create a logistic regression classifier\n",
    "    clf = linear_model.LogisticRegression(penalty='l2', C=c_val)\n",
    "    \n",
    "    # compute the 5-fold cross validation score of this classifier\n",
    "    scores = model_selection.cross_val_score(clf, Xtrain, ytrain, \n",
    "                                             cv=5,\n",
    "                                             scoring='accuracy')\n",
    "    accuracies.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(c_values, accuracies, marker='o') # plot using a log-scale on the x-axis\n",
    "plt.xlabel('Mean cross-validated accuracy')\n",
    "plt.ylabel('Value of C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the impact of having a very small C? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn lets us tune the parameter C automatically, by cross-validation on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegressionCV(Cs=10, \n",
    "                                        penalty='l2')\n",
    "clf.fit(Xtrain, ytrain)\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What values of C were tested? What is the accuracy now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Nearest neighbors\n",
    "\n",
    "[KNeighborsClassifier documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "\n",
    "The nearest neighbor algorithm classifies an observation according to the labels of the k nearest points in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a kNN classifier\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Apply the classifier to test data\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the accuracy of this classifier? Display its confusion matrix. How does it compare to the logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have a hyperparameter to fit: the number of nearest neighbors.\n",
    "\n",
    "Let us see how it impacts cross-validates performance on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of values for k\n",
    "k_values = np.array(np.linspace(3, 23, 10), dtype=int)\n",
    "print(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [] # where to store mean accuracy for each value of k\n",
    "for k_val in k_values:\n",
    "    # create a kNN classifier\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k_val)\n",
    "    \n",
    "    # compute the 5-fold cross validation score of this classifier\n",
    "    scores = model_selection.cross_val_score(clf, Xtrain, ytrain, \n",
    "                                             cv=10,\n",
    "                                             scoring='accuracy')\n",
    "    accuracies.append(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_values, accuracies, marker='o') \n",
    "plt.xlabel('Mean cross-validated accuracy')\n",
    "plt.ylabel('Value of k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the optimal number of nearest neighbors to use for this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Train a kNN that uses this optimal number of neighbors on the train set and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 SVM\n",
    "### 3.3.1 Linear SVM\n",
    "\n",
    "[LinearSVC documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "\n",
    "Let us start with a linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear SVM classifier\n",
    "clf = svm.LinearSVC(dual=False) # when number of samples > number of features, \n",
    "                                # solving the primal is more efficient.\n",
    "\n",
    "# Fit the classifier on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Apply the classifier to test data\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %.3f\" % metrics.accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the accuracy of this classifier? Display its confusion matrix. What was the value of the C parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use a grid search to optimize the parameter C.\n",
    "\n",
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a grid (here, a line) of parameters to explore\n",
    "param_grid = {'C': np.logspace(-5, 5, 11)}\n",
    "\n",
    "# define the base classifier\n",
    "clf = svm.LinearSVC(dual=False)\n",
    "\n",
    "# define the grid search\n",
    "gs = model_selection.GridSearchCV(clf, param_grid, cv=5, \n",
    "                                  scoring='accuracy')\n",
    "# train\n",
    "gs.fit(Xtrain, ytrain)\n",
    "\n",
    "# print the best score and corresponding parameter\n",
    "print(\"Best accuracy: %.3f\" % gs.best_score_)\n",
    "print(\"Optimal parameter:\", gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information regarding the cross-validation experiment are stored in `gs.cv_results_`. \n",
    "\n",
    "In particular, we can observe how the mean cross-validated accuracy varies with C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(np.array(gs.cv_results_['param_C'], dtype='float'), \n",
    "             gs.cv_results_['mean_test_score'], marker='o') # plot using a log-scale on the x-axis\n",
    "plt.xlabel('Mean cross-validated accuracy')\n",
    "plt.ylabel('Value of C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train an SVM with optimal C parameter on the train set and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear SVM classifier\n",
    "clf = svm.LinearSVC(dual=False, C=gs.best_params_['C'])\n",
    "\n",
    "# Fit the classifier on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Apply the classifier to test data\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ How does this classifier's accuracy compare to that of the logistic regression? Of the nearest neighbors? Look at the confusion matrix: is it always the same digits that are difficult to predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Kernel SVM\n",
    "\n",
    "Although our linear SVM already performs well, the power of SVMs typically come from their ability to solve the problem in a non-linear way, thanks to a kernel.\n",
    "\n",
    "[SVC documentation](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RBF SVM classifier\n",
    "clf = svm.SVC(kernel='rbf') \n",
    "\n",
    "# Fit the classifier on train data\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "# Apply the classifier to test data\n",
    "ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ What is the accuracy of this classifier? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Choose two parameters to optimize to try and improve this performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ Train the model with optimal parameters on the train set and evaluate it on the test set. Compare it to the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Random forests\n",
    "\n",
    "[RandomForestClassifier documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "Now you can try applying random forests to the Digits data. Refer to the documentation to create and evaluate a random forest classifier with default parameter, as well as to choose which parameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
